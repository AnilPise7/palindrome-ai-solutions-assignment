{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dddb6ee",
   "metadata": {},
   "source": [
    "# AI Solutions Engineer Interview Assignment – Palindrome Data\n",
    "\n",
    "This notebook implements an end‑to‑end analysis of synthetic WhatsApp‑style conversations between an AI health chatbot and clients. The goals are:\n",
    "\n",
    "1. **Ingest and parse** the conversation dataset.\n",
    "2. **Generate risk scores** for:\n",
    "   - HIV acquisition risk\n",
    "   - Mental health disorder risk\n",
    "3. **Produce a structured recommendation and care plan** aligned with high‑level principles from South African National Department of Health (NDOH) guidance.\n",
    "\n",
    "> **Important note**  \n",
    "> This notebook is for a technical interview task only. All risk scores and care plans here are simple rule‑based prototypes, **not clinical tools** and **not medical advice**. Any real‑world deployment would need expert clinical review, validation, and strict safety governance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "DATA_PATH = Path('health_ai_whatsapp_100_conversations_long.txt')\n",
    "assert DATA_PATH.exists(), f\"Dataset not found at {DATA_PATH.resolve()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a135ae0",
   "metadata": {},
   "source": [
    "## 1. Data ingestion and parsing\n",
    "\n",
    "The raw file contains multiple conversations separated by a line:\n",
    "\n",
    "```text\n",
    "========== Conversation ==========\n",
    "```\n",
    "\n",
    "Within each conversation, each message has the format:\n",
    "\n",
    "```text\n",
    "[01/01/2025, 08:00] User: Hi, I need help about something sensitive.\n",
    "```\n",
    "\n",
    "We will parse this into a tidy dataframe with columns:\n",
    "`conversation_id`, `timestamp_str`, `speaker`, `text`, `turn_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d142b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = DATA_PATH.read_text(encoding='utf-8')\n",
    "\n",
    "CONV_SEP = '========== Conversation =========='\n",
    "raw_conversations = [c.strip() for c in raw_text.split(CONV_SEP) if c.strip()]\n",
    "len(raw_conversations), raw_conversations[0][:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f944a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_str = r'^\\[(?P<timestamp>[^\\]]+)\\]\\s*(?P<speaker>[^:]+):\\s*(?P<text>.*)$'\n",
    "message_pattern = re.compile(pattern_str, re.MULTILINE)\n",
    "\n",
    "records = []\n",
    "for conv_id, conv in enumerate(raw_conversations, start=1):\n",
    "    for turn_idx, match in enumerate(message_pattern.finditer(conv), start=1):\n",
    "        records.append(\n",
    "            {\n",
    "                'conversation_id': conv_id,\n",
    "                'turn_index': turn_idx,\n",
    "                'timestamp_str': match.group('timestamp'),\n",
    "                'speaker': match.group('speaker').strip(),\n",
    "                'text': match.group('text').strip(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "df_msgs = pd.DataFrame(records)\n",
    "df_msgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1767d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msgs['speaker'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c5e5cb",
   "metadata": {},
   "source": [
    "## 2. Conversation‑level aggregation\n",
    "\n",
    "Risk scoring will happen at **conversation level**, based on all user messages in that chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_conversation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Concatenate all user utterances per conversation\n",
    "    user_text = (\n",
    "        df[df['speaker'].str.lower().str.contains('user')]\n",
    "        .groupby('conversation_id')['text']\n",
    "        .apply(lambda s: '\\n'.join(s))\n",
    "    )\n",
    "    # Concatenate all AI utterances per conversation (for context / later analysis)\n",
    "    ai_text = (\n",
    "        df[df['speaker'].str.lower().str.contains('ai')]\n",
    "        .groupby('conversation_id')['text']\n",
    "        .apply(lambda s: '\\n'.join(s))\n",
    "    )\n",
    "\n",
    "    agg = (\n",
    "        pd.DataFrame({'user_text': user_text})\n",
    "        .join(pd.DataFrame({'ai_text': ai_text}))\n",
    "        .reset_index()\n",
    "    )\n",
    "    return agg\n",
    "\n",
    "df_conv = aggregate_conversation(df_msgs)\n",
    "df_conv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7672fa8b",
   "metadata": {},
   "source": [
    "## 3. Simple lexicon‑based risk model\n",
    "\n",
    "Given we do not have labelled data, we use a **transparent rule‑based approach**:\n",
    "\n",
    "### HIV acquisition risk\n",
    "\n",
    "*High‑risk indicators* (e.g. unprotected sex, known HIV‑positive partner, multiple partners, needle sharing, STI symptoms) are assigned higher weights.\n",
    "\n",
    "### Mental‑health risk\n",
    "\n",
    "*Crisis indicators* (e.g. suicidal thoughts, self‑harm) and *moderate indicators* (e.g. persistent low mood, anxiety, insomnia) are scored separately.\n",
    "\n",
    "Scores are normalised to the **0–1** range and mapped to categorical risk levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword lexicons – deliberately simple and interpretable\n",
    "\n",
    "HIV_HIGH_KEYWORDS = [\n",
    "    'unprotected sex', 'no condom', 'without a condom', 'condom broke',\n",
    "    'multiple partners', 'many partners', 'sex worker', 'paid sex',\n",
    "    'needle', 'injecting drugs', 'shared syringe',\n",
    "    'hiv positive', 'partner is positive', 'sti', 'std', 'genital sore', 'ulcer',\n",
    "]\n",
    "\n",
    "HIV_MODERATE_KEYWORDS = [\n",
    "    'new partner', 'one night stand', 'hookup', 'blood contact',\n",
    "    'condom slipped', 'missed prep', 'missed pep',\n",
    "]\n",
    "\n",
    "MH_CRISIS_KEYWORDS = [\n",
    "    'suicide', 'suicidal', 'kill myself', 'end my life', 'want to die',\n",
    "    'self-harm', 'self harm', 'cut myself', 'overdose',\n",
    "]\n",
    "\n",
    "MH_MODERATE_KEYWORDS = [\n",
    "    'depressed', 'depression', 'anxious', 'anxiety', 'panic attack',\n",
    "    'no energy', \"can't sleep\", 'insomnia', 'worthless', 'hopeless',\n",
    "    'stressed', 'stress', 'burnt out', 'burnout',\n",
    "]\n",
    "\n",
    "def count_keyword_hits(text: str, keywords: List[str]) -> int:\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    text_lower = text.lower()\n",
    "    return sum(text_lower.count(k) for k in keywords)\n",
    "\n",
    "def normalise_score(raw: float, max_ref: float) -> float:\n",
    "    if max_ref <= 0:\n",
    "        return 0.0\n",
    "    return min(raw / max_ref, 1.0)\n",
    "\n",
    "def risk_level(score: float, low=0.25, high=0.6) -> str:\n",
    "    if score >= high:\n",
    "        return 'high'\n",
    "    elif score >= low:\n",
    "        return 'moderate'\n",
    "    return 'low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27712aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_conversation(text: str) -> Dict[str, float]:\n",
    "    \"\"\"Return raw and normalised scores for HIV and mental‑health risk.\"\"\"\n",
    "    hiv_raw = (\n",
    "        2 * count_keyword_hits(text, HIV_HIGH_KEYWORDS)\n",
    "        + 1 * count_keyword_hits(text, HIV_MODERATE_KEYWORDS)\n",
    "    )\n",
    "    mh_raw = (\n",
    "        3 * count_keyword_hits(text, MH_CRISIS_KEYWORDS)\n",
    "        + 1 * count_keyword_hits(text, MH_MODERATE_KEYWORDS)\n",
    "    )\n",
    "\n",
    "    hiv_score = normalise_score(hiv_raw, max_ref=6)  # heuristics\n",
    "    mh_score = normalise_score(mh_raw, max_ref=6)\n",
    "\n",
    "    return {\n",
    "        'hiv_raw': hiv_raw,\n",
    "        'mh_raw': mh_raw,\n",
    "        'hiv_score': hiv_score,\n",
    "        'mh_score': mh_score,\n",
    "        'hiv_level': risk_level(hiv_score),\n",
    "        'mh_level': risk_level(mh_score),\n",
    "    }\n",
    "\n",
    "# Test on a synthetic example\n",
    "example_text = \"I had unprotected sex with a new partner and I am very anxious and can't sleep.\"\n",
    "score_conversation(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9802e21",
   "metadata": {},
   "source": [
    "## 4. Apply risk scoring to all conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113c23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = df_conv['user_text'].apply(score_conversation).apply(pd.Series)\n",
    "df_scored = pd.concat([df_conv[['conversation_id', 'user_text']], scores], axis=1)\n",
    "df_scored.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scored[['hiv_level', 'mh_level']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3604f093",
   "metadata": {},
   "source": [
    "## 5. Recommendation and care‑plan generator\n",
    "\n",
    "Here we generate **non‑prescriptive**, high‑level guidance that *resembles* what a South African NDOH‑aligned triage system might propose. The aim is to show how an AI system can structure recommendations – **not** to replace clinicians.\n",
    "\n",
    "We:\n",
    "- Combine HIV and mental‑health risk levels.\n",
    "- Produce a short summary of concerns.\n",
    "- Suggest action steps: e.g. HIV testing, linkage to care, psycho‑social support, emergency referral if crisis keywords are detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f1cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendation(row: pd.Series) -> Dict[str, str]:\n",
    "    hiv_level = row['hiv_level']\n",
    "    mh_level = row['mh_level']\n",
    "    text = row['user_text'].lower()\n",
    "\n",
    "    summary_parts = []\n",
    "    if hiv_level != 'low':\n",
    "        summary_parts.append(f'HIV exposure risk appears **{hiv_level}** based on reported behaviour.')\n",
    "    else:\n",
    "        summary_parts.append('No explicit high‑risk sexual or blood‑exposure behaviour detected in the text; HIV risk appears **low** from conversation alone.')\n",
    "\n",
    "    if mh_level != 'low':\n",
    "        summary_parts.append(f'Mental‑health concern appears **{mh_level}** based on language suggesting distress.')\n",
    "    else:\n",
    "        summary_parts.append('No strong crisis language detected; mental‑health risk appears **low**, although stress is still possible.')\n",
    "\n",
    "    summary = ' '.join(summary_parts)\n",
    "\n",
    "    steps = []\n",
    "    # HIV‑related suggested actions (non‑clinical)\n",
    "    if hiv_level == 'high':\n",
    "        steps.append(\n",
    "            '- Offer **immediate HIV counselling and testing** at the nearest clinic and discuss options such as PEP/PrEP in line with local guidelines.'\n",
    "        )\n",
    "    elif hiv_level == 'moderate':\n",
    "        steps.append(\n",
    "            '- Encourage the client to attend an HIV testing service within the next few days and provide information on safer‑sex practices.'\n",
    "        )\n",
    "    else:\n",
    "        steps.append(\n",
    "            '- Provide general HIV prevention education (condom use, testing at routine intervals) and share information on local testing sites.'\n",
    "        )\n",
    "\n",
    "    # Mental‑health‑related suggested actions (non‑clinical)\n",
    "    crisis_present = any(kw in text for kw in MH_CRISIS_KEYWORDS)\n",
    "    if crisis_present:\n",
    "        steps.append(\n",
    "            '- Treat as **potential emergency**: advise immediate contact with local emergency services or same‑day in‑person mental‑health assessment; ensure the person is not left alone.'\n",
    "        )\n",
    "    elif mh_level == 'high':\n",
    "        steps.append(\n",
    "            '- Arrange a **priority referral** for a mental‑health assessment (e.g. psychologist/psychiatric nurse) and discuss safety planning.'\n",
    "        )\n",
    "    elif mh_level == 'moderate':\n",
    "        steps.append(\n",
    "            '- Offer counselling support, psycho‑education on stress, sleep, and coping skills; schedule follow‑up contact to monitor symptoms.'\n",
    "        )\n",
    "    else:\n",
    "        steps.append(\n",
    "            '- Offer brief reassurance, normalise seeking help early, and provide resources for support if symptoms worsen.'\n",
    "        )\n",
    "\n",
    "    plan_text = '\\n'.join(steps)\n",
    "    return {\n",
    "        'summary': summary,\n",
    "        'care_plan': plan_text,\n",
    "    }\n",
    "\n",
    "recs = df_scored.apply(generate_recommendation, axis=1).apply(pd.Series)\n",
    "df_final = pd.concat([df_scored, recs], axis=1)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d2f3e",
   "metadata": {},
   "source": [
    "## 6. Inspect a single case end‑to‑end\n",
    "\n",
    "Below we:\n",
    "1. Select a conversation by ID.\n",
    "2. Show the raw turns.\n",
    "3. Display the computed risk scores and generated care plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b7430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_conversation(conversation_id: int):\n",
    "    display(df_msgs[df_msgs['conversation_id'] == conversation_id])\n",
    "    display(\n",
    "        df_final[df_final['conversation_id'] == conversation_id][[\n",
    "            'hiv_score', 'hiv_level', 'mh_score', 'mh_level', 'summary', 'care_plan'\n",
    "        ]]\n",
    "    )\n",
    "\n",
    "# Example: inspect conversation 1\n",
    "show_conversation(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1eec19",
   "metadata": {},
   "source": [
    "## 7. Export conversation‑level outputs\n",
    "\n",
    "For convenience, we export the per‑conversation results to a CSV file. This could be used by downstream dashboards or reporting tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f80fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "OUTPUT_PATH = Path('conversation_risk_scores_and_plans.csv')\n",
    "df_final.to_csv(OUTPUT_PATH, index=False)\n",
    "OUTPUT_PATH.resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd00cf9",
   "metadata": {},
   "source": [
    "## 8. Limitations and next steps\n",
    "\n",
    "- This is a **rule‑based, lexicon‑driven prototype** – easy to explain but not calibrated.\n",
    "- Real‑world deployment would require:\n",
    "  - Larger, labelled datasets and supervised models (e.g. fine‑tuned transformers).\n",
    "  - Rigorous evaluation (sensitivity/specificity, fairness, and calibration). \n",
    "  - Alignment with up‑to‑date NDOH clinical guidelines, reviewed by domain experts.\n",
    "  - Strong safety controls (escalation flows, human‑in‑the‑loop, audit logging).\n",
    "- Future iterations could use:\n",
    "  - Sentence‑level classifiers for specific intents (e.g. *condom failure*, *suicidal ideation*).\n",
    "  - Context‑aware scoring that tracks how risk evolves across turns.\n",
    "  - Multi‑task learning to jointly model HIV and mental‑health risk."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
